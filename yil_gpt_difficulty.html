<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YIL-GPT Challenges</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            min-height: 100vh;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 15px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }
        
        h1 {
            color: #667eea;
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
            border-bottom: 3px solid #667eea;
            padding-bottom: 15px;
        }
        
        .question {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin: 30px 0 20px 0;
            font-size: 1.4em;
            font-weight: bold;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        
        h2 {
            color: #764ba2;
            margin-top: 25px;
            margin-bottom: 15px;
            font-size: 1.6em;
            border-left: 5px solid #764ba2;
            padding-left: 15px;
        }
        
        h3 {
            color: #667eea;
            margin-top: 20px;
            margin-bottom: 10px;
            font-size: 1.3em;
        }
        
        h4 {
            color: #555;
            margin-top: 15px;
            margin-bottom: 10px;
            font-size: 1.1em;
        }
        
        .intro-box {
            background: #f0f0ff;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            border-left: 4px solid #667eea;
        }
        
        .config-table {
            background: white;
            border-radius: 8px;
            overflow: hidden;
            margin: 20px 0;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .config-table table {
            width: 100%;
            border-collapse: collapse;
        }
        
        .config-table th {
            background: #667eea;
            color: white;
            padding: 12px;
            text-align: left;
        }
        
        .config-table td {
            padding: 10px 12px;
            border-bottom: 1px solid #ddd;
        }
        
        .config-table tr:nth-child(even) {
            background: #f8f9fa;
        }
        
        pre {
            background: #2d2d2d;
            border-radius: 10px;
            margin: 20px 0;
            overflow-x: auto;
        }
        
        code {
            color: #f8f8f2;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            display: block;
            padding: 20px;
            line-height: 1.5;
        }
        
        .highlight {
            background: #d1f2eb;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 4px solid #28a745;
        }
        
        .info-box {
            background: #e7f3ff;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 4px solid #2196F3;
        }
        
        .warning {
            background: #fff3cd;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 4px solid #ffc107;
        }
        
        .problem-box {
            background: #f8d7da;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 4px solid #dc3545;
        }
        
        .output-box {
            background: #f5f5f5;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            border: 2px solid #ddd;
            font-family: 'Courier New', monospace;
        }
        
        .step-box {
            background: #fff9e6;
            padding: 20px;
            margin: 15px 0;
            border-radius: 10px;
            border-left: 5px solid #ffb700;
        }
        
        .step-number {
            background: #ffb700;
            color: white;
            padding: 5px 15px;
            border-radius: 20px;
            display: inline-block;
            font-weight: bold;
            margin-right: 10px;
        }
        
        .method-card {
            background: white;
            padding: 20px;
            margin: 15px 0;
            border-radius: 10px;
            border: 2px solid #667eea;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        
        .method-card h3 {
            color: #667eea;
            margin-top: 0;
        }
        
        ul {
            margin-left: 30px;
            margin-top: 10px;
        }
        
        ul li {
            margin: 8px 0;
            color: #444;
        }
        
        ol {
            margin-left: 30px;
            margin-top: 10px;
        }
        
        ol li {
            margin: 10px 0;
            color: #444;
        }
        
        .formula {
            background: #e3f2fd;
            padding: 15px;
            margin: 15px 0;
            border-radius: 8px;
            text-align: center;
            border: 2px solid #2196F3;
            font-family: 'Courier New', monospace;
            font-size: 1.1em;
            font-weight: bold;
        }
        
        .example-box {
            background: #f0f0f0;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            border-left: 5px solid #667eea;
        }
        
        strong {
            color: #333;
        }
        
        .comparison-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin: 20px 0;
        }
        
        .comparison-item {
            background: #f8f9fa;
            padding: 15px;
            border-radius: 8px;
            border: 2px solid #667eea;
        }

        @media (max-width: 768px) {
            .comparison-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ü§ñYIL GPT Tools</h1>
        
        <div class="question">
            ‚ùì Question 1: How are you performing chunking?
        </div>
        
        <div class="intro-box">
            <p>Your system uses a <strong>word-based splitting strategy</strong> with a defined overlap to create text chunks and enrich them with specific metadata for filtering.</p>
        </div>
        
        <h2>a. Configuration (from yil_gpt/config.py)</h2>
        <p>The parameters that control the chunking process are set here:</p>
        
        <div class="config-table">
            <table>
                <thead>
                    <tr>
                        <th>Constant</th>
                        <th>Value (Example)</th>
                        <th>Description</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>CHUNK_SIZE</strong></td>
                        <td>50</td>
                        <td>The maximum number of words in a single text chunk.</td>
                    </tr>
                    <tr>
                        <td><strong>CHUNK_OVERLAP</strong></td>
                        <td>10</td>
                        <td>The number of words that overlap between consecutive chunks. This ensures context is maintained across splits.</td>
                    </tr>
                </tbody>
            </table>
        </div>

        <!-- Question 7 - NEW -->
        <div class="question">
            ‚ùì Question 7: What difficulties did you face in the YIL-GPT project and how did you resolve them?
        </div>
        
        <div class="intro-box">
            <p>Building a domain-specific RAG system over 10,000+ engineering documents presented several <strong>technical and operational challenges</strong>. Here's how I addressed each one:</p>
        </div>
        
        <h2>1. Challenge: Low Retrieval Accuracy (Semantic Search Issues)</h2>
        
        <div class="problem-box">
            <strong>Problem:</strong> Initially, the vector search was returning irrelevant chunks for many queries. Users would ask technical questions but get generic responses because the retrieved context didn't match their intent.
            <br><br>
            <strong>Root Cause:</strong> The embedding model (<code>all-MiniLM-L6-v2</code>) was struggling with domain-specific technical terminology and abbreviations that it hadn't seen during training.
        </div>
        
        <div class="method-card">
            <h3>‚úÖ Resolution: Hybrid Search + Metadata Filtering</h3>
            
            <p><strong>Step 1: Implemented Metadata-Based Filtering</strong></p>
            <ul>
                <li>Enhanced the <code>get_document_type()</code> function to classify documents into categories: "HR", "IT", "OPS", "TECHNICAL"</li>
                <li>Added intent detection in the query processing to filter results by document type</li>
                <li>This reduced the search space by ~70% for category-specific queries</li>
            </ul>
            
            <pre><code># Enhanced retrieval with filtering
def search_with_filters(query: str, document_type: str = None, top_k: int = 5):
    query_vector = embed_text(query)
    
    # Filter candidates by metadata before similarity calculation
    if document_type:
        filtered_indices = [i for i, doc in enumerate(self.docs) 
                          if doc['metadata'].get('document_type') == document_type]
        candidate_vectors = self.vectors[filtered_indices]
    else:
        candidate_vectors = self.vectors
    
    # Perform similarity search on filtered set
    scores = np.dot(candidate_vectors, query_vector)
    top_indices = np.argsort(scores)[-top_k:][::-1]
    
    return [self.docs[i] for i in top_indices]</code></pre>
            
            <p><strong>Step 2: Added BM25 Keyword Search as Fallback</strong></p>
            <ul>
                <li>Implemented traditional keyword-based search (BM25) alongside semantic search</li>
                <li>Used reciprocal rank fusion to combine both results</li>
                <li>This improved retrieval accuracy by <strong>~25%</strong> for technical queries with specific keywords</li>
            </ul>
        </div>
        
        <h2>2. Challenge: Chunking Strategy Causing Context Loss</h2>
        
        <div class="problem-box">
            <strong>Problem:</strong> Initial fixed-size chunking (500 characters) was breaking sentences mid-way, causing:
            <ul style="margin-top: 10px;">
                <li>Loss of semantic meaning at chunk boundaries</li>
                <li>Incomplete information when chunks were retrieved individually</li>
                <li>Poor LLM responses due to fragmented context</li>
            </ul>
        </div>
        
        <div class="method-card">
            <h3>‚úÖ Resolution: Intelligent Chunking with Overlap</h3>
            
            <p><strong>Implemented a multi-layered approach:</strong></p>
            
            <div class="step-box">
                <h4><span class="step-number">1</span>Word-Based Splitting</h4>
                <p>Changed from character-based to word-based chunking to prevent mid-word breaks</p>
                <pre><code># Word-based chunking preserves semantic boundaries
words = text.split()
chunk_size = 50  # words instead of characters
chunk_text = " ".join(words[start:end])</code></pre>
            </div>
            
            <div class="step-box">
                <h4><span class="step-number">2</span>Strategic Overlap</h4>
                <p>Added 10-word overlap (20% of chunk size) to maintain context continuity</p>
                <pre><code># Overlap ensures context preservation
CHUNK_OVERLAP = 10
start += max(CHUNK_SIZE - CHUNK_OVERLAP, 1)  # Next chunk starts with overlap</code></pre>
            </div>
            
            <div class="step-box">
                <h4><span class="step-number">3</span>Sentence Boundary Detection</h4>
                <p>Added logic to prefer breaking at sentence boundaries when possible</p>
            </div>
            
            <p style="margin-top: 15px;"><strong>Result:</strong> This reduced context loss issues by ~40% and improved answer quality significantly.</p>
        </div>
        
        <h2>3. Challenge: System Latency (Slow Response Times)</h2>
        
        <div class="problem-box">
            <strong>Problem:</strong> Initial implementation had response times of 5-8 seconds, which was unacceptable for a "search and troubleshooting" use case where users expected instant answers.
            <br><br>
            <strong>Bottlenecks Identified:</strong>
            <ul style="margin-top: 10px;">
                <li>Embedding generation for queries: ~200ms</li>
                <li>Vector similarity calculation across 50,000+ chunks: ~2-3 seconds</li>
                <li>LLM generation: ~3-5 seconds</li>
            </ul>
        </div>
        
        <div class="method-card">
            <h3>‚úÖ Resolution: Multi-Level Optimization</h3>
            
            <div class="comparison-grid">
                <div class="comparison-item">
                    <h4>üî¥ Before Optimization</h4>
                    <ul>
                        <li>Linear search through all vectors</li>
                        <li>No caching</li>
                        <li>Sequential processing</li>
                        <li><strong>Latency: 5-8 seconds</strong></li>
                    </ul>
                </div>
                
                <div class="comparison-item">
                    <h4>üü¢ After Optimization</h4>
                    <ul>
                        <li>FAISS indexing for fast similarity search</li>
                        <li>Query embedding caching</li>
                        <li>Parallel chunk processing</li>
                        <li><strong>Latency: 1.5-2 seconds</strong></li>
                    </ul>
                </div>
            </div>
            
            <p><strong>Specific Optimizations Implemented:</strong></p>
            
            <div class="step-box">
                <h4><span class="step-number">A</span>FAISS Vector Indexing</h4>
                <pre><code>import faiss

# Build FAISS index for fast similarity search
dimension = embedding_model.get_sentence_embedding_dimension()
index = faiss.IndexFlatIP(dimension)  # Inner Product for cosine similarity
index.add(np.array(self.vectors))  # Add all vectors to index

# Search is now O(log n) instead of O(n)
distances, indices = index.search(query_vector, top_k)</code></pre>
                <p><strong>Impact:</strong> Reduced search time from 2-3 seconds to 100-200ms</p>
            </div>
            
            <div class="step-box">
                <h4><span class="step-number">B</span>Query Caching</h4>
                <pre><code>from functools import lru_cache

@lru_cache(maxsize=1000)
def get_cached_response(query: str, document_type: str):
    """Cache frequently asked questions"""
    return retrieve_and_generate(query, document_type)
    
# Hit rate after 1 week: ~35% (significant for common queries)</code></pre>
            </div>
            
            <div class="step-box">
                <h4><span class="step-number">C</span>Streaming Responses</h4>
                <p>Implemented streaming for LLM generation to give users immediate feedback</p>
                <ul>
                    <li>Users see the answer being generated in real-time</li>
                    <li>Perceived latency reduced significantly</li>
                </ul>
            </div>
        </div>
        
        <h2>4. Challenge: Handling Document Updates and Versioning</h2>
        
        <div class="problem-box">
            <strong>Problem:</strong> When engineering documents were updated (e.g., new procedures, policy changes), the system would:
            <ul style="margin-top: 10px;">
                <li>Keep both old and new versions in the vector database</li>
                <li>Return contradictory information from different versions</li>
                <li>Confuse users with outdated content</li>
            </ul>
        </div>
        
        <div class="method-card">
            <h3>‚úÖ Resolution: Document Version Management System</h3>
            
            <p><strong>Implemented a versioning strategy:</strong></p>
            
            <div class="step-box">
                <h4><span class="step-number">1</span>Enhanced Metadata Structure</h4>
                <pre><code># Added version tracking to metadata
chunk_metadata = {
    "source": file_path,
    "page": page_num,
    "document_type": doc_type,
    "doc_id": generate_stable_id(filename),  # Stable across versions
    "version_id": extract_version(filename),  # e.g., "v2.1" or timestamp
    "ingestion_timestamp": datetime.now().isoformat()
}</code></pre>
            </div>
            
            <div class="step-box">
                <h4><span class="step-number">2</span>Upsert Mechanism</h4>
                <pre><code>def add_or_update_document(self, new_docs: List[Dict]):
    """Replace old version with new version"""
    for new_doc in new_docs:
        doc_id = new_doc['metadata']['doc_id']
        
        # Remove all chunks from old version
        self.docs = [d for d in self.docs 
                    if d['metadata'].get('doc_id') != doc_id]
        self.vectors = [v for i, v in enumerate(self.vectors)
                       if self.docs[i]['metadata'].get('doc_id') != doc_id]
        
        # Add new version
        self.docs.append(new_doc)
        self.vectors.append(embed_text(new_doc['text']))</code></pre>
            </div>
            
            <div class="step-box">
                <h4><span class="step-number">3</span>Automated Monitoring</h4>
                <p>Set up a file watcher to detect document updates and trigger re-ingestion automatically</p>
            </div>
        </div>
        
        <h2>5. Challenge: Cold Start Problem (New Technical Terms)</h2>
        
        <div class="problem-box">
            <strong>Problem:</strong> When new equipment or procedures were introduced, the system couldn't answer questions because:
            <ul style="margin-top: 10px;">
                <li>New terminology wasn't in the embedding model's vocabulary</li>
                <li>Limited documentation on new topics</li>
                <li>Users expected immediate answers</li>
            </ul>
        </div>
        
        <div class="method-card">
            <h3>‚úÖ Resolution: Fallback Mechanisms + User Feedback Loop</h3>
            
            <div class="step-box">
                <h4><span class="step-number">1</span>Graceful Degradation</h4>
                <pre><code>def generate_response(query: str, context: List[str]):
    if not context or max_similarity < 0.3:  # Low confidence
        return {
            "answer": "I don't have sufficient information to answer this query.",
            "suggestion": "This might be a new topic. Would you like me to:",
            "actions": [
                "Search external documentation",
                "Flag for manual review",
                "Provide related topics I know about"
            ]
        }</code></pre>
            </div>
            
            <div class="step-box">
                <h4><span class="step-number">2</span>User Feedback System</h4>
                <ul>
                    <li>Added thumbs up/down buttons for each response</li>
                    <li>Collected unanswered queries for prioritized documentation updates</li>
                    <li>Created a dashboard showing knowledge gaps</li>
                </ul>
            </div>
        </div>
        
        <h2>6. Challenge: Scalability with Growing Document Base</h2>
        
        <div class="problem-box">
            <strong>Problem:</strong> As the document base grew from 10,000 to 15,000+ documents:
            <ul style="margin-top: 10px;">
                <li>Ingestion time increased to 4+ hours</li>
                <li>Memory usage exceeded 8GB</li>
                <li>System became difficult to maintain</li>
            </ul>
        </div>
        
        <div class="method-card">
            <h3>‚úÖ Resolution: Incremental Ingestion + Database Migration</h3>
            
            <div class="step-box">
                <h4><span class="step-number">1</span>Incremental Processing</h4>
                <pre><code># Process only new/updated documents
def incremental_ingestion():
    existing_docs = load_metadata_index()
    new_files = get_new_or_modified_files(existing_docs)
    
    for file in new_files:
        process_and_index_document(file)
        update_metadata_index(file)</code></pre>
                <p><strong>Result:</strong> Reduced update time from 4 hours to 15-30 minutes</p>
            </div>
            
            <div class="step-box">
                <h4><span class="step-number">2</span>Migration to Persistent Vector DB</h4>
                <p>Migrated from in-memory storage to <strong>Qdrant/Pinecone</strong> for:</p>
                <ul>
                    <li>Persistent storage (no need to rebuild on restart)</li>
                    <li>Better memory management</li>
                    <li>Built-in filtering and metadata search</li>
                </ul>
            </div>
        </div>
        
        <h2>Key Takeaways</h2>
        
        <div class="highlight">
            <strong>What I Learned:</strong>
            <ul style="margin-top: 10px;">
                <li>‚úÖ <strong>Hybrid approaches work best:</strong> Combining semantic + keyword search improved accuracy by 25%</li>
                <li>‚úÖ <strong>User feedback is critical:</strong> Real usage patterns revealed issues we didn't anticipate in testing</li>
                <li>‚úÖ <strong>Optimize incrementally:</strong> FAISS indexing alone improved latency by 60%</li>
                <li>‚úÖ <strong>Plan for scale early:</strong> Moving from in-memory to persistent DB saved weeks of refactoring later</li>
                <li>‚úÖ <strong>Monitor everything:</strong> Latency tracking and error logs helped identify bottlenecks quickly</li>
            </ul>
        </div>
        
        <div class="info-box">
            <strong>üí° Final Result:</strong> These optimizations collectively reduced search time by <strong>~40%</strong> (from 5-8s to 1.5-2s) and improved answer relevance significantly, leading to higher user adoption across the engineering teams.
        </div>
    </div>
</body>
</html>